{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7cb0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2 import network, input_dim, hidden_dim, num_layers, char2oh, vocab \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sys import stdout\n",
    "    \n",
    "def encode(letter):\n",
    "    \"\"\"One-hot encoding of letter\"\"\"\n",
    "    return char2oh[letter]\n",
    "\n",
    "def decode(tensor):\n",
    "    \"\"\"Letter from one-hot encoding\"\"\"\n",
    "    index = tensor.view(-1).max(0)[1]\n",
    "    return vocab[index.item()]\n",
    "\n",
    "prompt = \"The next big invention \" #feed in a input prompt\n",
    "speech_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dab75cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next big invention KKKKK@KKKKKMKmTTKPKMKKL%yKKK<DKKLKmPKmKLKK4aK<%KKPKKLM%DMT@K)@4aMmKLKKKPK#PWK%KKK4KKPmP%@%KKKKPMKKMKKKMKMKLM@PKMhKm4K%PKMLKmKM)KL4KMPKLPKKKyMKDMyMKK#mhT0KvTmKPKKMPK%wTKLM4mKKmL<#KW#PKmL)KLKKKM0@MmmWKMKKKKPK14KM#KLKPTK4yK@L4lTTLK<@MPKLMK)KwMTyhKKwKKKPm%Mm,KM4MK4KK#%PKKK%4KKKMMK,mK%KMKTKmPLK@<TK@Pm#KyyT#KKK%K4%MKKKTK#P%4KM4K#KK#K@KKK<KKyK@KKMm<yMMP%MmKTKPMMMmKaK#LyKKLPdKLPW%4K%y#@MKKmKPWMKKLLMK@mP%KPKmPMmowPM4lmKKKKP%P4KKKPK4KmKmKLMMTMTKMKK41K#@KPLKgKKKMP)KP%KKmTmKPMLM4KKPMLmK%PKKK#PyPPMPK%KMMPMK<<KKKKPPP4KaTKTKMPWaM%K,PPyKK4gmKh%mP<TK4KL4TwKKw%KTK%T#%m%lMK4PK4MP%%K#MPMy#PKL%KPMMmK4LKLMK%m4P#TKP,KK@P4#LKKPmKTP#%PmMM4KKPm#MPKMmKP%@KLaKM@KK<MKKTKKmLKKMKKKP#mLKmMKKP#KMMTmKKK)MKKKLlPT@MMKKKmKPKKKPmLkKKKM%K0KP<KMK<K@KmKmKy@LKmMLKKKKKKKKKKKK%TK4KDP@K%KKMKPKPKmKK<KKKKKKKmPK)KKKKK%K4KlMKKMWKKKKKPMKK4#KmoKK@M%KPMK41KLKKMKKKKKyKK#K@KKKPKKTKl@@PPMKy1K#KMK4KMPPLK6KPmKMWKPLLKK#TKLKKmKMKK4M#%MPP@KPKLKMKKMKPM4%)L4KPKKLMK%WKK%KKMmPK%%KKmy@KmKKMKKKKKKKKKPKP4<L@MLKMKP#MK@KKKPK#yK%KKKKKKPLKMP@@%#KKK%M%4KKL"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/skxd6ygn2_xdqybw7hyxtc9h0000gn/T/ipykernel_14247/231301665.py:12: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  ip = Variable(encode(letter).view(1,1,-1), volatile=True)\n",
      "/var/folders/4l/skxd6ygn2_xdqybw7hyxtc9h0000gn/T/ipykernel_14247/231301665.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  ip = Variable(encode(output).view(1,1,-1), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    speaker = network(91, 128, 2)\n",
    "    speaker.load_state_dict(torch.load('./checkpoints/e10_3.0835.pth',map_location=torch.device('cpu')))\n",
    "    speaker.batch_size = 1\n",
    "   \n",
    "    speaker.reset()\n",
    "    \n",
    "    temperature = 0.55  \n",
    "    \n",
    "    for letter in prompt:\n",
    "        ip = Variable(encode(letter).view(1,1,-1), volatile=True)\n",
    "        output = decode(speaker(ip))\n",
    "        stdout.write(letter)\n",
    "    \n",
    "    for counter in range(speech_len):\n",
    "        ip = Variable(encode(output).view(1,1,-1), volatile=True)\n",
    "        output_dist = speaker(ip).data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        output = vocab[top_i]\n",
    "        stdout.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a40aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/skxd6ygn2_xdqybw7hyxtc9h0000gn/T/ipykernel_14247/1846499860.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ip = torch.tensor(encode(letter).view(1, 1, -1), dtype=torch.float32)  # Convert to tensor\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m letter \u001b[38;5;129;01min\u001b[39;00m prompt:\n\u001b[1;32m     20\u001b[0m     ip \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(letter)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     stdout\u001b[38;5;241m.\u001b[39mwrite(letter)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Assuming 'speech_len' is defined elsewhere\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Letter from one-hot encoding\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m index \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vocab[\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize the speaker network\n",
    "    speaker = network(91, 128, 2)\n",
    "    \n",
    "    # Load model weights onto the CPU\n",
    "    speaker.load_state_dict(torch.load('./checkpoints/e10_3.0805.pth', map_location=torch.device('cpu')))\n",
    "    speaker.batch_size = 1\n",
    "   \n",
    "    # Reset the speaker (ensure the network is initialized properly)\n",
    "    speaker.reset()\n",
    "    \n",
    "    # Set the temperature for sampling\n",
    "    temperature = 0.55  \n",
    "    \n",
    "    # Assuming 'prompt' is defined elsewhere\n",
    "    for letter in prompt:\n",
    "        ip = torch.tensor(encode(letter).view(1, 1, -1), dtype=torch.float32)  # Convert to tensor\n",
    "        output = decode(speaker(ip))\n",
    "        stdout.write(letter)\n",
    "    \n",
    "    # Assuming 'speech_len' is defined elsewhere\n",
    "    for counter in range(speech_len):\n",
    "        ip = torch.tensor(encode(output).view(1, 1, -1), dtype=torch.float32)  # Convert to tensor\n",
    "        output_dist = speaker(ip).view(-1).div(temperature).exp()  # Ensure it's a tensor\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        output = vocab[top_i]  # Assuming vocab is defined elsewhere\n",
    "        stdout.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc8e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d716e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
